version: "3.8"
services:
    inference:
        container_name: "yolov5-inference"
        build: "./inference"
        ports:
            - '5000:5000'
        volumes:
            - ./inference:/code
            - ./volumes/weights:/weights
        command: "uvicorn main:app --host 0.0.0.0 --port 5000 --reload"
        ipc: host
        shm_size: 1024M
        deploy:
            resources:
                reservations:
                    devices:
                        - capabilities: [gpu]

    train:
        container_name: "yolov5-train"
        build: "./train"
        shm_size: '2gb'
        command: "uvicorn main:app --host 0.0.0.0 --port 8000 --reload"
        environment:
            - RESPONSE_URL=http://127.0.0.1:8000/response
            - LOGGER_URL=http://127.0.0.1:8000/logger
            - IS_LOGGER_ON=False
        ports:
            - '8000:8000'
        volumes:
            - ./train:/code
            - ./volumes/weights:/weights
            - ./volumes/dataset:/dataset
        ipc: host
        deploy:
            resources:
                reservations:
                    devices:
                        - capabilities: [gpu]
