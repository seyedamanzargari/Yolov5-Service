version: "3.8"
services:
    inference:
        container_name: "yolov5-inference"
        build: "./backbone"
        ports:
            - '5000:5000'
        volumes:
            - ./backbone:/code
        command: "python3 app.py"
        environment:
            - MODEL_PATH=/code/weights/best.pt
        ipc: host
        shm_size: 1024M
        deploy:
            resources:
                reservations:
                    devices:
                        - capabilities: [gpu]

    train:
        container_name: "yolov5-train"
        build: "./train"
        shm_size: '2gb'
        command: "python3 main_train.py"
        environment:
            - RESPONSE_URL=http://127.0.0.1:8000/response
            - LOGGER_URL=http://127.0.0.1:8000/logger
            - IS_LOGGER_ON=False
        ports:
            - '8000:8000'
        volumes:
            - ./train:/code
            - ./volumes/weights:/code/weights
            - ./volumes/dataset:/code/dataset
        ipc: host
        deploy:
            resources:
                reservations:
                    devices:
                        - capabilities: [gpu]
